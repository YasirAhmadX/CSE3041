{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f3ee67",
   "metadata": {},
   "source": [
    "# Pandas DataFrame (Y@sir Ahmad 22MIA1064)  \n",
    "\n",
    "## Working with JSPN - JavaScript Object Notation   \n",
    "   \n",
    "JSON files basically are a string text of dictionary. \n",
    "\n",
    "> `'{\"name\":\"John\",\"age\":30}'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24346dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90aeb6e",
   "metadata": {},
   "source": [
    "### To read JSON file from a string  \n",
    "Create string of dictionary and use `json.loads()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a261860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John', 'age': 30, 'contact': [7282569632, 9912339726]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#JSON as string\n",
    "p = '{\"name\":\"John\",\"age\":30,\"contact\":[7282569632,9912339726]}'\n",
    "\n",
    "d = json.loads(p)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f39b9",
   "metadata": {},
   "source": [
    "### To read JSON file from directory   \n",
    "Open the JSON file and use `json.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1333c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fruit': 'Apple', 'size': 'Large', 'color': 'Red'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('fruit.json','r')\n",
    "d2 = json.load(file)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126975d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eebb63",
   "metadata": {},
   "source": [
    "## Saving data into JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa155390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Alex\", \"age\": 30, \"contact\": [7282569632, 9912339726]}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"name\": \"Alex\", \"age\": 30, \"contact\": [7282569632, 9912339726]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94fec5",
   "metadata": {},
   "source": [
    "### To put JSON dictionary into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc2f8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"John\", \"age\": 30, \"contact\": [7282569632, 9912339726]}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ = json.dumps(d) #dump as string\n",
    "dJ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51264cfe",
   "metadata": {},
   "source": [
    "### To put dictionary into JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a799aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DumpFile = open('JSONdump.json','w')\n",
    "json.dump(d,DumpFile)\n",
    "DumpFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db76ef",
   "metadata": {},
   "source": [
    "# Read JSON file to DataFrame   \n",
    "Use `pd.read_json(filepath)` to read the JSON file into dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "409d8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('sampledata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc97600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Maxpulse</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>409.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>117</td>\n",
       "      <td>145</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>175</td>\n",
       "      <td>282.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>117</td>\n",
       "      <td>148</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>60</td>\n",
       "      <td>105</td>\n",
       "      <td>140</td>\n",
       "      <td>290.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>145</td>\n",
       "      <td>300.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>60</td>\n",
       "      <td>115</td>\n",
       "      <td>145</td>\n",
       "      <td>310.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>320.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>75</td>\n",
       "      <td>125</td>\n",
       "      <td>150</td>\n",
       "      <td>330.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Duration  Pulse  Maxpulse  Calories\n",
       "0          60    110       130     409.1\n",
       "1          60    117       145     479.0\n",
       "2          60    103       135     340.0\n",
       "3          45    109       175     282.4\n",
       "4          45    117       148     406.0\n",
       "..        ...    ...       ...       ...\n",
       "164        60    105       140     290.8\n",
       "165        60    110       145     300.4\n",
       "166        60    115       145     310.2\n",
       "167        75    120       150     320.4\n",
       "168        75    125       150     330.4\n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d06ce",
   "metadata": {},
   "source": [
    "# Write DataFrame into JSON     \n",
    "Use `pd.to_json(filepath)` to write the DataFrame into JSON file  \n",
    "\n",
    "Formats available:   \n",
    "orient=  \n",
    "* split\n",
    "* records  \n",
    "* index  \n",
    "* values  \n",
    "* table  \n",
    "* columns  \n",
    "\n",
    "        * The format of the JSON string:\n",
    "    \n",
    "            - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
    "              'data' -> [values]}\n",
    "            - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
    "            - 'index' : dict like {index -> {column -> value}}\n",
    "            - 'columns' : dict like {column -> {index -> value}}\n",
    "            - 'values' : just the values array\n",
    "            - 'table' : dict like {'schema': {schema}, 'data': {data}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "952c7d5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Printer</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monitor</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tablet</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keyboard</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product  Price\n",
       "0  Computer   1200\n",
       "1   Printer    200\n",
       "2   Monitor    500\n",
       "3    Tablet    350\n",
       "4  Keyboard     80"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = {\"Product\":[\"Computer\",\"Printer\",\"Monitor\",\"Tablet\",\"Keyboard\"], \"Price\":[1200,200,500,350,80]}\n",
    "df = pd.DataFrame(data1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eb788a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"exported_json.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b4d505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_json in module pandas.core.generic:\n",
      "\n",
      "to_json(path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, orient: 'str | None' = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'str' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t' = True, indent: 'int | None' = None, storage_options: 'StorageOptions' = None) -> 'str | None' method of pandas.core.frame.DataFrame instance\n",
      "    Convert the object to a JSON string.\n",
      "    \n",
      "    Note NaN's and None will be converted to null and datetime objects\n",
      "    will be converted to UNIX timestamps.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str, path object, file-like object, or None, default None\n",
      "        String, path object (implementing os.PathLike[str]), or file-like\n",
      "        object implementing a write() function. If None, the result is\n",
      "        returned as a string.\n",
      "    orient : str\n",
      "        Indication of expected JSON string format.\n",
      "    \n",
      "        * Series:\n",
      "    \n",
      "            - default is 'index'\n",
      "            - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      "    \n",
      "        * DataFrame:\n",
      "    \n",
      "            - default is 'columns'\n",
      "            - allowed values are: {'split', 'records', 'index', 'columns',\n",
      "              'values', 'table'}.\n",
      "    \n",
      "        * The format of the JSON string:\n",
      "    \n",
      "            - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      "              'data' -> [values]}\n",
      "            - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      "            - 'index' : dict like {index -> {column -> value}}\n",
      "            - 'columns' : dict like {column -> {index -> value}}\n",
      "            - 'values' : just the values array\n",
      "            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      "    \n",
      "            Describing the data, where data component is like ``orient='records'``.\n",
      "    \n",
      "    date_format : {None, 'epoch', 'iso'}\n",
      "        Type of date conversion. 'epoch' = epoch milliseconds,\n",
      "        'iso' = ISO8601. The default depends on the `orient`. For\n",
      "        ``orient='table'``, the default is 'iso'. For all other orients,\n",
      "        the default is 'epoch'.\n",
      "    double_precision : int, default 10\n",
      "        The number of decimal places to use when encoding\n",
      "        floating point values.\n",
      "    force_ascii : bool, default True\n",
      "        Force encoded string to be ASCII.\n",
      "    date_unit : str, default 'ms' (milliseconds)\n",
      "        The time unit to encode to, governs timestamp and ISO8601\n",
      "        precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "        microsecond, and nanosecond respectively.\n",
      "    default_handler : callable, default None\n",
      "        Handler to call if object cannot otherwise be converted to a\n",
      "        suitable format for JSON. Should receive a single argument which is\n",
      "        the object to convert and return a serialisable object.\n",
      "    lines : bool, default False\n",
      "        If 'orient' is 'records' write out line-delimited json format. Will\n",
      "        throw ValueError if incorrect 'orient' since others are not\n",
      "        list-like.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        Set to ``None`` for no compression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for faster compression and to create\n",
      "        a reproducible gzip archive:\n",
      "        ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    index : bool, default True\n",
      "        Whether to include the index values in the JSON string. Not\n",
      "        including the index (``index=False``) is only supported when\n",
      "        orient is 'split' or 'table'.\n",
      "    indent : int, optional\n",
      "       Length of whitespace used to indent each record.\n",
      "    \n",
      "       .. versionadded:: 1.0.0\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting json format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_json : Convert a JSON string to pandas object.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      "    indent the output but does insert newlines. Currently, ``indent=0``\n",
      "    and the default ``indent=None`` are equivalent in pandas, though this\n",
      "    may change in a future release.\n",
      "    \n",
      "    ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      "    This stores the version of `pandas` used in the latest revision of the\n",
      "    schema.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import json\n",
      "    >>> df = pd.DataFrame(\n",
      "    ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      "    ...     index=[\"row 1\", \"row 2\"],\n",
      "    ...     columns=[\"col 1\", \"col 2\"],\n",
      "    ... )\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"split\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"columns\": [\n",
      "            \"col 1\",\n",
      "            \"col 2\"\n",
      "        ],\n",
      "        \"index\": [\n",
      "            \"row 1\",\n",
      "            \"row 2\"\n",
      "        ],\n",
      "        \"data\": [\n",
      "            [\n",
      "                \"a\",\n",
      "                \"b\"\n",
      "            ],\n",
      "            [\n",
      "                \"c\",\n",
      "                \"d\"\n",
      "            ]\n",
      "        ]\n",
      "    }\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "    Note that index labels are not preserved with this encoding.\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"records\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    [\n",
      "        {\n",
      "            \"col 1\": \"a\",\n",
      "            \"col 2\": \"b\"\n",
      "        },\n",
      "        {\n",
      "            \"col 1\": \"c\",\n",
      "            \"col 2\": \"d\"\n",
      "        }\n",
      "    ]\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"index\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"row 1\": {\n",
      "            \"col 1\": \"a\",\n",
      "            \"col 2\": \"b\"\n",
      "        },\n",
      "        \"row 2\": {\n",
      "            \"col 1\": \"c\",\n",
      "            \"col 2\": \"d\"\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"columns\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"col 1\": {\n",
      "            \"row 1\": \"a\",\n",
      "            \"row 2\": \"c\"\n",
      "        },\n",
      "        \"col 2\": {\n",
      "            \"row 1\": \"b\",\n",
      "            \"row 2\": \"d\"\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"values\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    [\n",
      "        [\n",
      "            \"a\",\n",
      "            \"b\"\n",
      "        ],\n",
      "        [\n",
      "            \"c\",\n",
      "            \"d\"\n",
      "        ]\n",
      "    ]\n",
      "    \n",
      "    Encoding with Table Schema:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"table\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"schema\": {\n",
      "            \"fields\": [\n",
      "                {\n",
      "                    \"name\": \"index\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"col 1\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"col 2\",\n",
      "                    \"type\": \"string\"\n",
      "                }\n",
      "            ],\n",
      "            \"primaryKey\": [\n",
      "                \"index\"\n",
      "            ],\n",
      "            \"pandas_version\": \"1.4.0\"\n",
      "        },\n",
      "        \"data\": [\n",
      "            {\n",
      "                \"index\": \"row 1\",\n",
      "                \"col 1\": \"a\",\n",
      "                \"col 2\": \"b\"\n",
      "            },\n",
      "            {\n",
      "                \"index\": \"row 2\",\n",
      "                \"col 1\": \"c\",\n",
      "                \"col 2\": \"d\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff482a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
